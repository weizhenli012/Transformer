{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3000],\n",
      "        [0.6000],\n",
      "        [0.9000]])\n",
      "tensor([[[[0.1000, 0.2000, 0.3000],\n",
      "          [0.4000, 0.5000, 0.6000],\n",
      "          [0.7000, 0.8000, 0.9000]]]])\n",
      "tensor([[[[ 1.0000e-01, -1.0000e+09, -1.0000e+09],\n",
      "          [ 4.0000e-01, -1.0000e+09, -1.0000e+09],\n",
      "          [ 7.0000e-01, -1.0000e+09, -1.0000e+09]]]])\n",
      "torch.Size([0, 3])\n",
      "tensor([[1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "scores = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "print(scores[:,-1:])\n",
    "mask = torch.tensor([[1, 0, 0]])\n",
    "scores= scores.unsqueeze(0).unsqueeze(0)\n",
    "print(scores)\n",
    "scores = scores.masked_fill(mask == 0, -1e9)\n",
    "print(scores)\n",
    "e = torch.empty(0, 3)\n",
    "f = torch.ones(1, 3)\n",
    "g = torch.cat((e, f), dim=0)\n",
    "print(e.shape)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 768])\n",
      "torch.Size([2, 6, 768])\n",
      "tensor([[[-0.6045,  1.3061,  1.8412,  ...,  1.4684, -0.3996,  0.9207],\n",
      "         [ 0.3479,  0.7857,  2.6157,  ...,  1.3424, -0.6106,  1.2924],\n",
      "         [ 0.2968, -0.2764,  2.9504,  ...,  1.8682, -0.7492,  1.3036],\n",
      "         [ 0.3244,  0.3033,  0.7407,  ...,  1.8151, -0.2391,  2.2699],\n",
      "         [-0.4322,  0.4339, -0.1183,  ...,  1.6096, -0.3874,  2.3086],\n",
      "         [-0.7347,  1.4958, -0.8436,  ...,  1.6217, -0.1354,  2.4185]],\n",
      "\n",
      "        [[-0.0915,  1.6476,  1.9834,  ...,  0.6351, -0.1314,  1.3702],\n",
      "         [ 0.1282,  0.9600,  2.6880,  ...,  0.9991, -0.7791,  0.9617],\n",
      "         [ 1.0561,  0.4818,  1.5933,  ...,  0.9836,  0.0146,  2.3497],\n",
      "         [ 0.2164,  0.2182,  0.3952,  ...,  1.2688,  0.1375,  2.4563],\n",
      "         [-0.5478,  0.3075, -0.5693,  ...,  1.2885,  0.0537,  2.2451],\n",
      "         [-1.1079,  1.4365, -0.4291,  ...,  1.3681, -0.0697,  2.0996]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer import Bert, Transformer\n",
    "vocab_size = 1024\n",
    "seq = arr = torch.tensor([[1,1,1,1,0,0,0],[1,1,1,0,0,0,0]])\n",
    "dec = torch.tensor([[1,1,1,0,0,0],[1,1,0,0,0,0]])\n",
    "logits = Bert.BERT(vocab_size=vocab_size,num_heads=2,num_layers=1)(seq)\n",
    "print(logits.shape)\n",
    "model = Transformer.Transformer(1024,1024,num_heads=2,num_layers=1)\n",
    "output, logitss = model(seq,dec)\n",
    "print(logitss.shape)\n",
    "print(logitss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1, 493, 425, 579, 320, 152, 627, 148, 425, 261, 841],\n",
      "        [  1, 535, 227, 576, 284, 841, 460, 676, 980, 261, 980]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "vocab_size = 1024\n",
    "seq = arr = torch.tensor([[2,3,4,5,0,0,0],[1,2,3,0,0,0,0]])\n",
    "dec = torch.tensor([[1],[1]])\n",
    "model = Transformer.Transformer(1024,1024,num_heads=2,num_layers=3)\n",
    "model.eval()\n",
    "#output, logitss = model(seq,dec)\n",
    "for i in range(10):\n",
    "    logits, _ = model(seq,dec)\n",
    "    pred = torch.softmax(logits[:,-1,:],dim=-1)\n",
    "    next_token = torch.argmax(pred,dim=-1)\n",
    "    dec = torch.cat([dec,next_token.unsqueeze(1)],dim=-1)\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1, 493,  86, 414, 841, 718, 294, 841, 214, 425, 882],\n",
      "        [  1, 535, 568, 980, 535, 568, 754, 261, 980, 535, 568]])\n"
     ]
    }
   ],
   "source": [
    "model.initial_cache(True)\n",
    "model.eval()\n",
    "dec = torch.tensor([[1],[1]])\n",
    "for i in range(10):\n",
    "    logits, _ = model(seq,dec)\n",
    "    pred = torch.softmax(logits[:,-1,:],dim=-1)\n",
    "    next_token = torch.argmax(pred,dim=-1)\n",
    "    dec = torch.cat([dec,next_token.unsqueeze(1)],dim=-1)\n",
    "print(dec)\n",
    "model.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1, 493, 425, 579, 320, 152, 627, 148, 425, 261, 841],\n",
      "        [  1, 535, 227, 576, 284, 841, 460, 676, 980, 261, 980]])\n"
     ]
    }
   ],
   "source": [
    "model.remove_cache()\n",
    "model.eval()\n",
    "dec = torch.tensor([[1],[1]])\n",
    "for i in range(10):\n",
    "    logits, _ = model(seq,dec)\n",
    "    pred = torch.softmax(logits[:,-1,:],dim=-1)\n",
    "    next_token = torch.argmax(pred,dim=-1)\n",
    "    dec = torch.cat([dec,next_token.unsqueeze(1)],dim=-1)\n",
    "print(dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [[1, 1, 1], 1]}\n",
      "[{'a': [[1, 1, 1], 1]}]\n",
      "[{'self_attn': [None, None], 'enc_attn': [None, None]}, {'self_attn': [None, None], 'enc_attn': [None, None]}, {'self_attn': [None, None], 'enc_attn': [None, None]}]\n"
     ]
    }
   ],
   "source": [
    "def revise(list4=None):\n",
    "    if list4[0] is None:\n",
    "        list4[0] = [1,1,1]\n",
    "    return 0\n",
    "\n",
    "def revise2(list1):\n",
    "    revise(list1[\"a\"])\n",
    "    print(list1)\n",
    "    return 0\n",
    "\n",
    "def revise3(list2):\n",
    "    revise2(list2[0])\n",
    "    return 0\n",
    "\n",
    "a = [{\"a\":[None,1]}]\n",
    "revise3(a)\n",
    "print(a)\n",
    "cache= [\n",
    "                {\"self_attn\":[\n",
    "                    None, None\n",
    "                ],\n",
    "                \"enc_attn\":[\n",
    "                    None, None\n",
    "                ]\n",
    "                }\n",
    "                for _ in range(3)]\n",
    "print(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,   95, 1014,  816,  377,  272,  219,  983,   90, 1014,  816],\n",
      "        [   1,   95, 1014,  349,  219,  351,  123,  478,  830,  478,  830]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "vocab_size = 1024\n",
    "seq = arr = torch.tensor([[1,1,1,1,0,0,0],[1,1,1,0,0,0,0]])\n",
    "dec = torch.tensor([[1],[1]])\n",
    "model = Transformer.Transformer(1024,1024,num_heads=2,num_layers=2)\n",
    "#output, logitss = model(seq,dec)\n",
    "for i in range(10):\n",
    "    logits, _ = model(seq,dec)\n",
    "    pred = torch.softmax(logits[:,-1,:],dim=-1)\n",
    "    next_token = torch.argmax(pred,dim=-1)\n",
    "    dec = torch.cat([dec,next_token.unsqueeze(1)],dim=-1)\n",
    "print(dec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
